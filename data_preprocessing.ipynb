{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/Serra/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (27108, 19)\n",
            "\n",
            "Columns: ['Unnamed: 0', 'Mekan_Adı', 'Kullanıcı_Adı', 'Yorum', 'Puan', 'Yorum_Tarihi', 'Restoran_Kategorisi', 'Restoran_Toplam_Yorum_Sayısı', 'Ortalama_Restoran_Puanı', 'Restoran_Adresi', 'sentiment_score', 'label', 'AI_Result', 'Tat', 'Hizmet', 'Ortam', 'Fiyat-Performans', 'Menü Çeşitliliği', 'Temizlik']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('lastt.csv')\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nColumns:\", df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1.1 Veri Hazırlığı & Temizlik\n",
        "\n",
        "## 1. Null Değer Kontrolü\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Null value counts per column:\n",
            "Unnamed: 0                          0\n",
            "Mekan_Adı                           0\n",
            "Kullanıcı_Adı                       0\n",
            "Yorum                               0\n",
            "Puan                                0\n",
            "Yorum_Tarihi                        0\n",
            "Restoran_Kategorisi                 0\n",
            "Restoran_Toplam_Yorum_Sayısı        0\n",
            "Ortalama_Restoran_Puanı             0\n",
            "Restoran_Adresi                     0\n",
            "sentiment_score                     3\n",
            "label                               3\n",
            "AI_Result                           1\n",
            "Tat                             10595\n",
            "Hizmet                          12499\n",
            "Ortam                           19167\n",
            "Fiyat-Performans                20356\n",
            "Menü Çeşitliliği                25165\n",
            "Temizlik                        23473\n",
            "dtype: int64\n",
            "\n",
            "Null value percentages per column:\n",
            "Unnamed: 0                       0.000000\n",
            "Mekan_Adı                        0.000000\n",
            "Kullanıcı_Adı                    0.000000\n",
            "Yorum                            0.000000\n",
            "Puan                             0.000000\n",
            "Yorum_Tarihi                     0.000000\n",
            "Restoran_Kategorisi              0.000000\n",
            "Restoran_Toplam_Yorum_Sayısı     0.000000\n",
            "Ortalama_Restoran_Puanı          0.000000\n",
            "Restoran_Adresi                  0.000000\n",
            "sentiment_score                  0.011067\n",
            "label                            0.011067\n",
            "AI_Result                        0.003689\n",
            "Tat                             39.084403\n",
            "Hizmet                          46.108160\n",
            "Ortam                           70.706065\n",
            "Fiyat-Performans                75.092224\n",
            "Menü Çeşitliliği                92.832374\n",
            "Temizlik                        86.590674\n",
            "dtype: float64\n",
            "\n",
            "Columns containing null values: ['sentiment_score', 'label', 'AI_Result', 'Tat', 'Hizmet', 'Ortam', 'Fiyat-Performans', 'Menü Çeşitliliği', 'Temizlik']\n"
          ]
        }
      ],
      "source": [
        "# Check null values in each column\n",
        "null_counts = df.isnull().sum()\n",
        "print(\"Null value counts per column:\")\n",
        "print(null_counts)\n",
        "\n",
        "# Calculate percentage of null values\n",
        "null_percentages = (null_counts / len(df)) * 100\n",
        "print(\"\\nNull value percentages per column:\")\n",
        "print(null_percentages)\n",
        "\n",
        "# List columns with null values\n",
        "columns_with_nulls = null_counts[null_counts > 0].index.tolist()\n",
        "print(\"\\nColumns containing null values:\", columns_with_nulls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Null value counts per column:\n",
            "Unnamed: 0                          0\n",
            "Mekan_Adı                           0\n",
            "Kullanıcı_Adı                       0\n",
            "Yorum                               0\n",
            "Puan                                0\n",
            "Yorum_Tarihi                        0\n",
            "Restoran_Kategorisi                 0\n",
            "Restoran_Toplam_Yorum_Sayısı        0\n",
            "Ortalama_Restoran_Puanı             0\n",
            "Restoran_Adresi                     0\n",
            "sentiment_score                     0\n",
            "label                               0\n",
            "AI_Result                           0\n",
            "Tat                             10592\n",
            "Hizmet                          12497\n",
            "Ortam                           19164\n",
            "Fiyat-Performans                20353\n",
            "Menü Çeşitliliği                25161\n",
            "Temizlik                        23470\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df = df.replace('', np.nan)\n",
        "df = df.dropna(subset=['sentiment_score', 'label', 'AI_Result'], how='any')\n",
        "null_counts = df.isnull().sum()\n",
        "print(\"Null value counts per column:\")\n",
        "print(null_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Kategori Skorlarının Normalizasyonu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 27104 entries, 0 to 27107\n",
            "Data columns (total 19 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   Unnamed: 0                    27104 non-null  int64  \n",
            " 1   Mekan_Adı                     27104 non-null  object \n",
            " 2   Kullanıcı_Adı                 27104 non-null  object \n",
            " 3   Yorum                         27104 non-null  object \n",
            " 4   Puan                          27104 non-null  int64  \n",
            " 5   Yorum_Tarihi                  27104 non-null  object \n",
            " 6   Restoran_Kategorisi           27104 non-null  object \n",
            " 7   Restoran_Toplam_Yorum_Sayısı  27104 non-null  int64  \n",
            " 8   Ortalama_Restoran_Puanı       27104 non-null  float64\n",
            " 9   Restoran_Adresi               27104 non-null  object \n",
            " 10  sentiment_score               27104 non-null  float64\n",
            " 11  label                         27104 non-null  object \n",
            " 12  AI_Result                     27104 non-null  object \n",
            " 13  Tat                           16512 non-null  object \n",
            " 14  Hizmet                        14607 non-null  object \n",
            " 15  Ortam                         7940 non-null   float64\n",
            " 16  Fiyat-Performans              6751 non-null   float64\n",
            " 17  Menü Çeşitliliği              1943 non-null   float64\n",
            " 18  Temizlik                      3634 non-null   float64\n",
            "dtypes: float64(6), int64(3), object(10)\n",
            "memory usage: 4.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Problematic cells that could not be converted to float:\n",
            "11696    {'Roast beef pizza': 1.0, 'Cannoli tatlısı': -...\n",
            "19776                                       Balıklar taze.\n",
            "Name: Tat, dtype: object\n"
          ]
        }
      ],
      "source": [
        "col = 'Tat'  # or any column you want\n",
        "# Try to convert, marking errors as NaN\n",
        "converted = pd.to_numeric(df[col], errors='coerce')\n",
        "# Find problematic cells (where conversion failed but value is not null/empty)\n",
        "problematic = df.loc[converted.isna() & df[col].notna(), col]\n",
        "print(\"⚠️ Problematic cells that could not be converted to float:\")\n",
        "print(problematic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_check = ['Tat', 'Hizmet']\n",
        "for col in cols_to_check:\n",
        "    converted = pd.to_numeric(df[col], errors='coerce')\n",
        "    # Drop problematic rows\n",
        "    df = df.loc[~(converted.isna() & df[col].notna())].copy()\n",
        "    # Convert the column to float\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Tat'] = df['Tat'].astype(float)\n",
        "df['Hizmet'] = df['Hizmet'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized Ortalama_Restoran_Puanı: Min=0.00, Max=1.00\n",
            "Normalized sentiment_score: Min=0.00, Max=1.00\n",
            "Normalized Ortam: Min=0.00, Max=1.00\n",
            "Normalized Fiyat-Performans: Min=0.00, Max=1.00\n",
            "Normalized Menü Çeşitliliği: Min=0.00, Max=1.00\n",
            "Normalized Temizlik: Min=0.00, Max=1.00\n"
          ]
        }
      ],
      "source": [
        "# Assuming we have category score columns, let's normalize them to 0-1 range\n",
        "# First, identify category score columns (you might need to adjust this based on your actual column names)\n",
        "# Select columns that contain 'kategori' or 'score' in the name AND are float type\n",
        "category_columns = [\n",
        "    col for col in df.columns \n",
        "    if  (pd.api.types.is_float_dtype(df[col]))]\n",
        "\n",
        "if category_columns:\n",
        "    # Min-Max normalization for category scores\n",
        "    for col in category_columns:\n",
        "        min_val = df[col].min()\n",
        "        max_val = df[col].max()\n",
        "        if pd.notnull(min_val) and pd.notnull(max_val) and max_val != min_val:  # avoid division by zero\n",
        "            df[f'{col}_normalized'] = (df[col] - min_val) / (max_val - min_val)\n",
        "            print(f\"Normalized {col}: Min={df[f'{col}_normalized'].min():.2f}, Max={df[f'{col}_normalized'].max():.2f}\")\n",
        "        else:\n",
        "            print(f\"Skipped {col}: constant or empty values\")\n",
        "else:\n",
        "    print(\"No category score float columns found. Please specify the correct column names.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Adres Parsing (Şehir, İlçe Çıkarma)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "İl dağılımı (top 10):\n",
            "Il\n",
            "Ankara    26206\n",
            "Name: count, dtype: int64\n",
            "\n",
            "İlçe dağılımı (top 10):\n",
            "Ilce\n",
            "Çankaya          4717\n",
            "Etimesgut        3626\n",
            "Keçiören         3218\n",
            "Altındağ         2962\n",
            "Mamak            2903\n",
            "Pursaklar        2421\n",
            "Beypazarı        1630\n",
            "Sincan           1460\n",
            "Kahramankazan    1230\n",
            "Yenimahalle      1208\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "\n",
        "# Full list of Turkish provinces (İl)\n",
        "TR_CITIES = {'ankara','istanbul','izmir'}\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    \"\"\"Basic normalize: unicode, collapse spaces, trim.\"\"\"\n",
        "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
        "    s = re.sub(r'\\s+', ' ', s).strip(' ,.;-')\n",
        "    return s\n",
        "\n",
        "def _clean_piece(s: str) -> str:\n",
        "    \"\"\"Drop postal codes & extra symbols from a piece likely holding İlçe.\"\"\"\n",
        "    s = re.sub(r'\\b\\d{4,6}\\b', ' ', s)      # remove postal codes like 06490\n",
        "    s = re.sub(r'[,.;]', ' ', s)\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    return s\n",
        "\n",
        "def _turkish_title(s: str) -> str:\n",
        "    \"\"\"Simple title-case that preserves Turkish chars reasonably.\"\"\"\n",
        "    # Fix common dotted-i artifacts if present\n",
        "    s = s.replace('i̇', 'i').replace('İ', 'İ')\n",
        "    return s.title()\n",
        "\n",
        "def extract_location_info(address: str):\n",
        "    \"\"\"Return (Ilce, Il) with Turkish casing; None, None if not found.\"\"\"\n",
        "    if pd.isna(address):\n",
        "        return None, None\n",
        "\n",
        "    addr = _norm(address)\n",
        "\n",
        "    # 1) Strong pattern: \"... <ilçe> / <il>\" at the END of address\n",
        "    # Allow letters, Turkish diacritics, dots and spaces in ilçe; only letters in il\n",
        "    m = re.search(r'([A-Za-zÇĞİIÖŞÜçğıiöşü\\.\\-\\s]+)\\s*/\\s*([A-Za-zÇĞİIÖŞÜçğıiöşü]+)\\s*$', addr)\n",
        "    if m:\n",
        "        raw_ilce = _clean_piece(m.group(1))\n",
        "        raw_il   = _clean_piece(m.group(2))\n",
        "        il_l = raw_il.lower()\n",
        "        if il_l in TR_CITIES:\n",
        "            ilce = _turkish_title(raw_ilce.split()[-1]) if raw_ilce else None\n",
        "            il   = _turkish_title(raw_il)\n",
        "            return ilce or None, il\n",
        "\n",
        "    # 2) No slash? Try to detect a city name near the end of string\n",
        "    # Find last occurrence of a known city token\n",
        "    tokens = [t.strip(' ,.;') for t in addr.split()]\n",
        "    lowers = [t.lower() for t in tokens]\n",
        "    city_pos = None\n",
        "    for i in range(len(lowers)-1, -1, -1):\n",
        "        if lowers[i] in TR_CITIES:\n",
        "            city_pos = i\n",
        "            break\n",
        "\n",
        "    if city_pos is not None:\n",
        "        il = _turkish_title(tokens[city_pos])\n",
        "        # Guess district as the closest previous alpha token skipping numbers/abbr\n",
        "        # e.g., \"... 06490 Çankaya Ankara\" -> take \"Çankaya\"\n",
        "        ilce = None\n",
        "        for j in range(city_pos-1, -1, -1):\n",
        "            token = tokens[j]\n",
        "            if re.fullmatch(r'\\d+|no:?|sk\\.?|cd\\.?|mah\\.?|mahallesi', token.lower()):\n",
        "                continue\n",
        "            if re.search(r'[A-Za-zÇĞİIÖŞÜçğıiöşü]', token):\n",
        "                ilce = _turkish_title(token)\n",
        "                break\n",
        "        return ilce, il\n",
        "\n",
        "    # 3) Give up if we can't confidently parse\n",
        "    return None, None\n",
        "\n",
        "# ---- Apply to your DataFrame ----\n",
        "address_column = 'Restoran_Adresi'  # change if needed\n",
        "if address_column in df.columns:\n",
        "    pairs = df[address_column].apply(extract_location_info)\n",
        "    df[['Ilce', 'Il']] = pd.DataFrame(pairs.tolist(), index=df.index)\n",
        "\n",
        "    # Quick sanity prints\n",
        "    print(\"İl dağılımı (top 10):\")\n",
        "    print(df['Il'].value_counts(dropna=True).head(10))\n",
        "    print(\"\\nİlçe dağılımı (top 10):\")\n",
        "    print(df['Ilce'].value_counts(dropna=True).head(10))\n",
        "else:\n",
        "    print(f\"Address column '{address_column}' not found. Available columns:\", df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Mekan_Adı</th>\n",
              "      <th>Kullanıcı_Adı</th>\n",
              "      <th>Yorum</th>\n",
              "      <th>Puan</th>\n",
              "      <th>Yorum_Tarihi</th>\n",
              "      <th>Restoran_Kategorisi</th>\n",
              "      <th>Restoran_Toplam_Yorum_Sayısı</th>\n",
              "      <th>Ortalama_Restoran_Puanı</th>\n",
              "      <th>sentiment_score</th>\n",
              "      <th>...</th>\n",
              "      <th>Menü Çeşitliliği</th>\n",
              "      <th>Temizlik</th>\n",
              "      <th>Ortalama_Restoran_Puanı_normalized</th>\n",
              "      <th>sentiment_score_normalized</th>\n",
              "      <th>Ortam_normalized</th>\n",
              "      <th>Fiyat-Performans_normalized</th>\n",
              "      <th>Menü Çeşitliliği_normalized</th>\n",
              "      <th>Temizlik_normalized</th>\n",
              "      <th>Ilce</th>\n",
              "      <th>Il</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>aynen_street_food</td>\n",
              "      <td>Meric Esmebasi</td>\n",
              "      <td>Ankarada denenmesi gereken burger’cilerin en b...</td>\n",
              "      <td>5</td>\n",
              "      <td>2024-11-20</td>\n",
              "      <td>Restoran</td>\n",
              "      <td>208</td>\n",
              "      <td>4.7</td>\n",
              "      <td>0.994092</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.997103</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Çankaya</td>\n",
              "      <td>Ankara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>aynen_street_food</td>\n",
              "      <td>Berkay ÇOBANOĞLU</td>\n",
              "      <td>Mükemmel bir mekan Güleryüz ve lezzet konusund...</td>\n",
              "      <td>5</td>\n",
              "      <td>2024-11-20</td>\n",
              "      <td>Restoran</td>\n",
              "      <td>208</td>\n",
              "      <td>4.7</td>\n",
              "      <td>0.996734</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.998424</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Çankaya</td>\n",
              "      <td>Ankara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>aynen_street_food</td>\n",
              "      <td>Ozan Özkan</td>\n",
              "      <td>Aynen burger çok iyiydi. Özellikle içerisinde ...</td>\n",
              "      <td>5</td>\n",
              "      <td>2024-11-20</td>\n",
              "      <td>Restoran</td>\n",
              "      <td>208</td>\n",
              "      <td>4.7</td>\n",
              "      <td>0.934129</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.967116</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Çankaya</td>\n",
              "      <td>Ankara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>aynen_street_food</td>\n",
              "      <td>Salih Karagöz</td>\n",
              "      <td>Ankaradaki favori hamburgercilerimden. Özellik...</td>\n",
              "      <td>5</td>\n",
              "      <td>2024-10-20</td>\n",
              "      <td>Restoran</td>\n",
              "      <td>208</td>\n",
              "      <td>4.7</td>\n",
              "      <td>0.954556</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.977331</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Çankaya</td>\n",
              "      <td>Ankara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>aynen_street_food</td>\n",
              "      <td>Alp Ankara</td>\n",
              "      <td>Hamburgeri ve patatesi çok lezzetli. Soğan hal...</td>\n",
              "      <td>5</td>\n",
              "      <td>2024-10-20</td>\n",
              "      <td>Restoran</td>\n",
              "      <td>208</td>\n",
              "      <td>4.7</td>\n",
              "      <td>-0.976560</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.011592</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Çankaya</td>\n",
              "      <td>Ankara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27097</th>\n",
              "      <td>27105</td>\n",
              "      <td>aynen_street_food</td>\n",
              "      <td>Toprak Bircan</td>\n",
              "      <td>Patatesleri aşırı aşırı aşırı yağlı. Biz beğen...</td>\n",
              "      <td>2</td>\n",
              "      <td>2025-03-20</td>\n",
              "      <td>Restoran</td>\n",
              "      <td>208</td>\n",
              "      <td>4.7</td>\n",
              "      <td>-0.999584</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.000078</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Çankaya</td>\n",
              "      <td>Ankara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27098</th>\n",
              "      <td>27106</td>\n",
              "      <td>aynen_street_food</td>\n",
              "      <td>KÖKSAL BAĞDU</td>\n",
              "      <td>Ayak üstü Google yorumlarıyla gittiğimiz bir y...</td>\n",
              "      <td>5</td>\n",
              "      <td>2025-03-20</td>\n",
              "      <td>Restoran</td>\n",
              "      <td>208</td>\n",
              "      <td>4.7</td>\n",
              "      <td>-0.947900</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.025925</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Çankaya</td>\n",
              "      <td>Ankara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27099</th>\n",
              "      <td>27107</td>\n",
              "      <td>aynen_street_food</td>\n",
              "      <td>Rümeysa Çakmak</td>\n",
              "      <td>Gerçekten en başarılı en lezzetli hamburgerler...</td>\n",
              "      <td>5</td>\n",
              "      <td>2025-03-20</td>\n",
              "      <td>Restoran</td>\n",
              "      <td>208</td>\n",
              "      <td>4.7</td>\n",
              "      <td>0.968671</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.984390</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Çankaya</td>\n",
              "      <td>Ankara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27100</th>\n",
              "      <td>27108</td>\n",
              "      <td>aynen_street_food</td>\n",
              "      <td>Umut Yıldırım</td>\n",
              "      <td>10 masalı bir işletme burgerlar çok güzel özel...</td>\n",
              "      <td>5</td>\n",
              "      <td>2025-02-20</td>\n",
              "      <td>Restoran</td>\n",
              "      <td>208</td>\n",
              "      <td>4.7</td>\n",
              "      <td>0.982163</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.991137</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Çankaya</td>\n",
              "      <td>Ankara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27101</th>\n",
              "      <td>27109</td>\n",
              "      <td>aynen_street_food</td>\n",
              "      <td>Begüm</td>\n",
              "      <td>Çok severek yiyoruz fakat son zamanlarda patat...</td>\n",
              "      <td>4</td>\n",
              "      <td>2025-01-20</td>\n",
              "      <td>Restoran</td>\n",
              "      <td>208</td>\n",
              "      <td>4.7</td>\n",
              "      <td>-0.998694</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.000523</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Çankaya</td>\n",
              "      <td>Ankara</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26200 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0          Mekan_Adı     Kullanıcı_Adı  \\\n",
              "0               0  aynen_street_food    Meric Esmebasi   \n",
              "1               1  aynen_street_food  Berkay ÇOBANOĞLU   \n",
              "2               2  aynen_street_food        Ozan Özkan   \n",
              "3               3  aynen_street_food     Salih Karagöz   \n",
              "4               4  aynen_street_food        Alp Ankara   \n",
              "...           ...                ...               ...   \n",
              "27097       27105  aynen_street_food     Toprak Bircan   \n",
              "27098       27106  aynen_street_food      KÖKSAL BAĞDU   \n",
              "27099       27107  aynen_street_food    Rümeysa Çakmak   \n",
              "27100       27108  aynen_street_food     Umut Yıldırım   \n",
              "27101       27109  aynen_street_food             Begüm   \n",
              "\n",
              "                                                   Yorum  Puan Yorum_Tarihi  \\\n",
              "0      Ankarada denenmesi gereken burger’cilerin en b...     5   2024-11-20   \n",
              "1      Mükemmel bir mekan Güleryüz ve lezzet konusund...     5   2024-11-20   \n",
              "2      Aynen burger çok iyiydi. Özellikle içerisinde ...     5   2024-11-20   \n",
              "3      Ankaradaki favori hamburgercilerimden. Özellik...     5   2024-10-20   \n",
              "4      Hamburgeri ve patatesi çok lezzetli. Soğan hal...     5   2024-10-20   \n",
              "...                                                  ...   ...          ...   \n",
              "27097  Patatesleri aşırı aşırı aşırı yağlı. Biz beğen...     2   2025-03-20   \n",
              "27098  Ayak üstü Google yorumlarıyla gittiğimiz bir y...     5   2025-03-20   \n",
              "27099  Gerçekten en başarılı en lezzetli hamburgerler...     5   2025-03-20   \n",
              "27100  10 masalı bir işletme burgerlar çok güzel özel...     5   2025-02-20   \n",
              "27101  Çok severek yiyoruz fakat son zamanlarda patat...     4   2025-01-20   \n",
              "\n",
              "      Restoran_Kategorisi  Restoran_Toplam_Yorum_Sayısı  \\\n",
              "0                Restoran                           208   \n",
              "1                Restoran                           208   \n",
              "2                Restoran                           208   \n",
              "3                Restoran                           208   \n",
              "4                Restoran                           208   \n",
              "...                   ...                           ...   \n",
              "27097            Restoran                           208   \n",
              "27098            Restoran                           208   \n",
              "27099            Restoran                           208   \n",
              "27100            Restoran                           208   \n",
              "27101            Restoran                           208   \n",
              "\n",
              "       Ortalama_Restoran_Puanı  sentiment_score  ... Menü Çeşitliliği  \\\n",
              "0                          4.7         0.994092  ...              NaN   \n",
              "1                          4.7         0.996734  ...              NaN   \n",
              "2                          4.7         0.934129  ...              NaN   \n",
              "3                          4.7         0.954556  ...              NaN   \n",
              "4                          4.7        -0.976560  ...             -0.7   \n",
              "...                        ...              ...  ...              ...   \n",
              "27097                      4.7        -0.999584  ...              NaN   \n",
              "27098                      4.7        -0.947900  ...              0.5   \n",
              "27099                      4.7         0.968671  ...              NaN   \n",
              "27100                      4.7         0.982163  ...              NaN   \n",
              "27101                      4.7        -0.998694  ...              NaN   \n",
              "\n",
              "      Temizlik  Ortalama_Restoran_Puanı_normalized  \\\n",
              "0          NaN                               0.925   \n",
              "1          NaN                               0.925   \n",
              "2          NaN                               0.925   \n",
              "3          NaN                               0.925   \n",
              "4          NaN                               0.925   \n",
              "...        ...                                 ...   \n",
              "27097      NaN                               0.925   \n",
              "27098      NaN                               0.925   \n",
              "27099      NaN                               0.925   \n",
              "27100      NaN                               0.925   \n",
              "27101      NaN                               0.925   \n",
              "\n",
              "       sentiment_score_normalized  Ortam_normalized  \\\n",
              "0                        0.997103               NaN   \n",
              "1                        0.998424               1.0   \n",
              "2                        0.967116               NaN   \n",
              "3                        0.977331               NaN   \n",
              "4                        0.011592               NaN   \n",
              "...                           ...               ...   \n",
              "27097                    0.000078               NaN   \n",
              "27098                    0.025925               NaN   \n",
              "27099                    0.984390               NaN   \n",
              "27100                    0.991137               NaN   \n",
              "27101                    0.000523               NaN   \n",
              "\n",
              "       Fiyat-Performans_normalized  Menü Çeşitliliği_normalized  \\\n",
              "0                              NaN                          NaN   \n",
              "1                              NaN                          NaN   \n",
              "2                              NaN                          NaN   \n",
              "3                              NaN                          NaN   \n",
              "4                              NaN                         0.15   \n",
              "...                            ...                          ...   \n",
              "27097                         0.05                          NaN   \n",
              "27098                          NaN                         0.75   \n",
              "27099                          NaN                          NaN   \n",
              "27100                         0.85                          NaN   \n",
              "27101                         0.15                          NaN   \n",
              "\n",
              "       Temizlik_normalized     Ilce      Il  \n",
              "0                      NaN  Çankaya  Ankara  \n",
              "1                      NaN  Çankaya  Ankara  \n",
              "2                      NaN  Çankaya  Ankara  \n",
              "3                      NaN  Çankaya  Ankara  \n",
              "4                      NaN  Çankaya  Ankara  \n",
              "...                    ...      ...     ...  \n",
              "27097                  NaN  Çankaya  Ankara  \n",
              "27098                  NaN  Çankaya  Ankara  \n",
              "27099                  NaN  Çankaya  Ankara  \n",
              "27100                  NaN  Çankaya  Ankara  \n",
              "27101                  NaN  Çankaya  Ankara  \n",
              "\n",
              "[26200 rows x 26 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop(columns=['extracted_city', 'extracted_district', 'Restoran_Adresi'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Ilce\n",
              "Çankaya          4711\n",
              "Etimesgut        3620\n",
              "Keçiören         3210\n",
              "Altındağ         2950\n",
              "Mamak            2903\n",
              "Pursaklar        2405\n",
              "Beypazarı        1630\n",
              "Sincan           1451\n",
              "Kahramankazan    1228\n",
              "Yenimahalle      1208\n",
              "Elmadağ           346\n",
              "Gölbaşı           175\n",
              "Eryaman            90\n",
              "Çayyolu            88\n",
              "Kalecik            64\n",
              "35;;A              53\n",
              "No:66/C            15\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Ilce\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1.2 NLP Altyapısı Kurma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e134c827c7804422b4a3b78681f9c5db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43ea92293b3c4f2fb5d4916820da1089",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e3d90d1cefd4a428e3cad4dd664e317",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a127d02c79b4087917ed5fda2f21dd5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48c0b6aae6054db9b7a46ee372002726",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fff4c0ce221487ba6e9713ce3f5f18e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e57a339e9214fcfbf65a1ace61830ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0767573453164073b98be2daa975ebea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b75e64dc77c54c109e7dcca7f55eed1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2546c95d843946e9af1b4b302f69725e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token:         Bu | Lemma:         bu | POS: DET\n",
            "Token:   restoran | Lemma:   restoran | POS: NOUN\n",
            "Token:        çok | Lemma:        çok | POS: ADV\n",
            "Token:      güzel | Lemma:      güzel | POS: ADJ\n",
            "Token:          . | Lemma:          . | POS: PUNCT\n",
            "Token:   Yemekler | Lemma:      yemek | POS: NOUN\n",
            "Token:     lezzet | Lemma:     lezzet | POS: NOUN\n",
            "Token:         li | Lemma:         li | POS: ADP\n",
            "Token:         ve | Lemma:         ve | POS: CCONJ\n",
            "Token:     servis | Lemma:     servis | POS: NOUN\n",
            "Token:      hızlı | Lemma:      hızlı | POS: ADJ\n",
            "Token:          . | Lemma:          . | POS: PUNCT\n",
            "\n",
            "Embeddings: (1, 384)\n",
            "\n",
            "TF-IDF: (1, 7) ['güzel' 'hızlı' 'lezzet' 'li' 'restoran' 'servis' 'yemek']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import stanza\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "\n",
        "# Download Turkish model if not already present\n",
        "stanza.download(\"tr\")\n",
        "nlp_stanza = stanza.Pipeline(\"tr\", processors=\"tokenize,pos,lemma\", use_gpu=torch.cuda.is_available())\n",
        "\n",
        "# Stopword set\n",
        "TR_STOP = {\"ve\",\"veya\",\"ile\",\"de\",\"da\",\"ki\",\"bu\",\"şu\",\"o\",\"bir\",\"çok\",\"az\",\"en\",\"mi\",\"mu\",\"mı\",\"mü\",\n",
        "           \"için\",\"gibi\",\"ama\",\"fakat\",\"hem\",\"daha\",\"her\",\"şey\",\"şimdi\",\"ne\",\"niçin\",\"neden\",\"çünkü\",\n",
        "           \"olan\",\"oldu\",\"oluyor\",\"yani\",\"ise\",\"ya\",\"ya da\",\"şöyle\"}\n",
        "\n",
        "def clean_token(t: str) -> str:\n",
        "    t = t.lower()\n",
        "    t = re.sub(r\"[^\\wçğıöşüâîû]\", \"\", t)\n",
        "    return t\n",
        "\n",
        "def tr_lemma_tokenizer(text: str):\n",
        "    doc = nlp_stanza(text)\n",
        "    toks = []\n",
        "    for sent in doc.sentences:\n",
        "        for w in sent.words:\n",
        "            lemma = clean_token(w.lemma or w.text)\n",
        "            if lemma and lemma not in TR_STOP:\n",
        "                toks.append(lemma)\n",
        "    return toks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# KONTROL GEREK \n",
        "Token:  burger’cilerin | Lemma:       burgeroci | POS: ADJ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 100 rows from df['Yorum'].\n",
            "Embeddings shape: (100, 384)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF shape: (100, 2416)\n",
            "Vocab size: 2416\n",
            "Feature sample (first 30): ['1' '1 lokma' '10' '10 adet' '10 numar' '100' '100 gr' '1010'\n",
            " '1010 mekan' '12' '12 adet' '1215' '1215 te' '150' '150 tl' '175tl'\n",
            " '175tl dene' '180' '180 tl' '2' '2 kilo' '20' '20 tane' '20 tl' '4'\n",
            " '4 kişi' '4 çeşit' '40' '40 derece' '5']\n",
            "\n",
            "=== Row 1 ===\n",
            "Ankarada denenmesi gereken burger’cilerin en başında geliyor\n",
            "Çok başarılı\n",
            "Token:        Ankarada | Lemma:          ankara | POS: NOUN\n",
            "Token:       denenmesi | Lemma:            dene | POS: VERB\n",
            "Token:         gereken | Lemma:           gerek | POS: VERB\n",
            "Token:  burger’cilerin | Lemma:       burgeroci | POS: ADJ\n",
            "Token:              en | Lemma:              en | POS: ADV\n",
            "Token:         başında | Lemma:             baş | POS: NOUN\n",
            "Token:         geliyor | Lemma:             gel | POS: VERB\n",
            "Token:             Çok | Lemma:             çok | POS: ADV\n",
            "Token:        başarılı | Lemma:        başarılı | POS: ADJ\n",
            "\n",
            "=== Row 2 ===\n",
            "Mükemmel bir mekan Güleryüz ve lezzet konusunda beklenti sınırlarınızı zorlayacak bir yer tüm sevdiklerinizi toplayıp gelin. Deneyim sonrası bana teşekkür edeceksiniz.\n",
            "Token:        Mükemmel | Lemma:        mükemmel | POS: ADJ\n",
            "Token:             bir | Lemma:             bir | POS: DET\n",
            "Token:           mekan | Lemma:           mekan | POS: NOUN\n",
            "Token:        Güleryüz | Lemma:        Güleryüz | POS: PROPN\n",
            "Token:              ve | Lemma:              ve | POS: CCONJ\n",
            "Token:          lezzet | Lemma:          lezzet | POS: NOUN\n",
            "Token:       konusunda | Lemma:            konu | POS: NOUN\n",
            "Token:        beklenti | Lemma:        beklenti | POS: NOUN\n",
            "Token:   sınırlarınızı | Lemma:           sınır | POS: NOUN\n",
            "Token:      zorlayacak | Lemma:           zorla | POS: VERB\n",
            "Token:             bir | Lemma:             bir | POS: DET\n",
            "Token:             yer | Lemma:             yer | POS: NOUN\n",
            "Token:             tüm | Lemma:             tüm | POS: DET\n",
            "Token:  sevdiklerinizi | Lemma:          sevdik | POS: NOUN\n",
            "Token:        toplayıp | Lemma:           topla | POS: VERB\n",
            "Token:           gelin | Lemma:             gel | POS: VERB\n",
            "Token:               . | Lemma:               . | POS: PUNCT\n",
            "Token:         Deneyim | Lemma:           deney | POS: NOUN\n",
            "Token:         sonrası | Lemma:           sonra | POS: NOUN\n",
            "Token:            bana | Lemma:             ben | POS: PRON\n",
            "Token:        teşekkür | Lemma:        teşekkür | POS: NOUN\n",
            "Token:     edeceksiniz | Lemma:              et | POS: VERB\n",
            "Token:               . | Lemma:               . | POS: PUNCT\n",
            "\n",
            "=== Row 3 ===\n",
            "Aynen burger çok iyiydi. Özellikle içerisinde bulunan tiftik ete bayıldık. Kesinlikle denenmesi gerekiyor.\n",
            "Token:           Aynen | Lemma:           aynen | POS: ADV\n",
            "Token:          burger | Lemma:          burger | POS: NOUN\n",
            "Token:             çok | Lemma:             çok | POS: ADV\n",
            "Token:             iyi | Lemma:             iyi | POS: ADJ\n",
            "Token:             ydi | Lemma:               i | POS: AUX\n",
            "Token:               . | Lemma:               . | POS: PUNCT\n",
            "Token:       Özellikle | Lemma:       özellikle | POS: ADV\n",
            "Token:      içerisinde | Lemma:           içeri | POS: NOUN\n",
            "Token:         bulunan | Lemma:             bul | POS: VERB\n",
            "Token:          tiftik | Lemma:          tiftik | POS: NOUN\n",
            "Token:             ete | Lemma:              et | POS: NOUN\n",
            "Token:        bayıldık | Lemma:           bayıl | POS: VERB\n",
            "Token:               . | Lemma:               . | POS: PUNCT\n",
            "Token:      Kesinlikle | Lemma:        kesinlik | POS: NOUN\n",
            "Token:       denenmesi | Lemma:            dene | POS: VERB\n",
            "Token:       gerekiyor | Lemma:           gerek | POS: VERB\n",
            "Token:               . | Lemma:               . | POS: PUNCT\n"
          ]
        }
      ],
      "source": [
        "# --- Take first 100 non-empty rows from df[\"Yorum\"] ---\n",
        "assert 'Yorum' in df.columns, \"Column 'Yorum' not found in df.\"\n",
        "texts = (\n",
        "    df['Yorum']\n",
        "      .dropna()\n",
        "      .astype(str)\n",
        "      .map(lambda s: s.strip())\n",
        "      .loc[lambda s: s.ne('')]\n",
        "      .head(100)\n",
        "      .tolist()\n",
        ")\n",
        "print(f\"Processing {len(texts)} rows from df['Yorum'].\")\n",
        "\n",
        "# --- Embeddings ---\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "embed_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', device=device)\n",
        "embeddings = embed_model.encode(texts)\n",
        "print(\"Embeddings shape:\", embeddings.shape)  # (N, 384)\n",
        "\n",
        "# --- TF-IDF (lemma-based) ---\n",
        "tfidf = TfidfVectorizer(\n",
        "    tokenizer=tr_lemma_tokenizer,\n",
        "    lowercase=False,\n",
        "    ngram_range=(1,2),\n",
        "    max_df=0.95\n",
        ")\n",
        "X = tfidf.fit_transform(texts)\n",
        "feat_names = tfidf.get_feature_names_out()\n",
        "print(\"TF-IDF shape:\", X.shape)\n",
        "print(\"Vocab size:\", len(feat_names))\n",
        "print(\"Feature sample (first 30):\", feat_names[:30])\n",
        "\n",
        "# --- Detailed token/lemma/POS print for the first few rows (adjust MAX_PRINT) ---\n",
        "MAX_PRINT = 3  # set to 100 if you want all\n",
        "for i, text in enumerate(texts[:MAX_PRINT], 1):\n",
        "    print(f\"\\n=== Row {i} ===\")\n",
        "    print(text)\n",
        "    doc = nlp_stanza(text)\n",
        "    for s in doc.sentences:\n",
        "        for w in s.words:\n",
        "            print(f\"Token: {w.text:>15} | Lemma: {w.lemma:>15} | POS: {w.upos}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
